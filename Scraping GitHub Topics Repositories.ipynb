{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1 style=\"color:Orange;font-size:170%;\"> Scraping Top Repositories for Topics on GitHub </h1>\n",
    "\n",
    "<img src=\"https://i.imgur.com/6zM7JBq.png\" width=\"1000\">\n",
    "\n",
    "Web scraping is the process of extracting and parsing data from websites in an automated fashion using a computer program. It's a useful technique for creating datasets for research and learning. GitHub is a web-based version-control and collaboration platform for software developers where you can upload your own code and projects. For scraping this website we will use a library for python called [Beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) which will help us to download and parse the html webpage. After downloading the page we will extract the content we are looking for and save it in a dataframe using [pandas](https://pandas.pydata.org/docs/) and save all the data collected in a csv file's.\n",
    "The link where we will scrap the content can be found [here](https://github.com/topic).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outline:\n",
    "This are the steps we will follow:\n",
    "- We're gonna to scrape [https://github.com/topics](https://github.com/topics)\n",
    "- we'll get a list of topics. For each topic, we'll get the topic title, page URL, and topic description\n",
    "- For each topic, we'll get the top 25 repositories in the topic from the topic page.\n",
    "- For each repository we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic, we'll create a CSV file in the following format:\n",
    "\n",
    "```\n",
    "> Repo Name,Username,Stars,URL\n",
    "> three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
    "> libgdx,libgdx,18300,https://github.com/libgdx/libgdx\n",
    "\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"desousa-andreas/scraping-top-repositories-for-topics-on-github\" on https://jovian.ai/\r\n",
      "[jovian] Committed successfully! https://jovian.ai/desousa-andreas/scraping-top-repositories-for-topics-on-github\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "'https://jovian.ai/desousa-andreas/scraping-top-repositories-for-topics-on-github'"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jovian\n",
    "project_name='Scraping Top Repositories for Topics on GitHub'\n",
    "jovian.commit(project=project_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scrape the list of topics from GitHub\n",
    "\n",
    "The first step of the process is to use requests to download and parse our web page. This process will be use few times so will be convenient write a function which take a url as input and return a BeautifulSoup object containing the html code.\n",
    "The steps are as follow:\n",
    "- Use Requests to download the html\n",
    "- Use bs4 for parse and extract the information\n",
    "- Return a bs object\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_topic_page(topic_url):\n",
    "    \"\"\"\n",
    "    This function scrap a designed webpage at url address and return a parsed BeautifulSoup containing the website\n",
    "    Lib needed:\n",
    "        import requests\n",
    "    :param topic_url: website address to scrap\n",
    "    :return: BeautifulSoup doc\n",
    "    \"\"\"\n",
    "\n",
    "    # download the page\n",
    "    r = requests.get(topic_url)\n",
    "    # check response\n",
    "    if r.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # parse beautiful soup\n",
    "    topic_doc = BeautifulSoup(r.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try out our function, check the output type and try to find the `a` tag for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "bs4.BeautifulSoup"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://github.com/topics'\n",
    "doc = get_topic_page(url)\n",
    "type(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "<a class=\"px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content\" href=\"#start-of-content\">Skip to content</a>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('a')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create some helper function to parse some information from the topic page.\n",
    "\n",
    "The `get_topic_title` can be used to get the list of the topics title's. To get topic title we can pick `p` tag's with `class = f3 lh-condensed mb-0 mt-1 Link--primary` as shown on the image.\n",
    "We use the inspect functionality of the browser to detect the right tag and class.\n",
    "\n",
    "![](https://i.imgur.com/ONm9jvi.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function take as input a bs object where will search and append to a dictionary all the topics titles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def get_topic_title(doc):\n",
    "    \"\"\"\n",
    "    This function retrieve the titles of the topics.\n",
    "    :param doc: Beautifulsoup Object\n",
    "    :return: a list\n",
    "    \"\"\"\n",
    "\n",
    "    selected_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.findAll('p', class_ = selected_class)\n",
    "\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "\n",
    "    return  topic_titles\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try out our function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "(30,\n ['3D',\n  'Ajax',\n  'Algorithm',\n  'Amp',\n  'Android',\n  'Angular',\n  'Ansible',\n  'API',\n  'Arduino',\n  'ASP.NET'])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = get_topic_title(doc)\n",
    "len(titles), titles[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see we have a list of 30 titles. Similarly we have another 2 functions for get the topic description `get_topic_descs` and the topic url `get_topic_url`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    \"\"\"\n",
    "    This function retrieve the description of the topics.\n",
    "    :param doc: Beautifulsoup Object\n",
    "    :return: a list\n",
    "    \"\"\"\n",
    "\n",
    "    selected_class = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.findAll('p', class_ = selected_class)\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "\n",
    "    return topic_descs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "['3D modeling is the process of virtually developing the surface and structure of a 3D object.',\n 'Ajax is a technique for creating interactive web applications.',\n 'Algorithms are self-contained sequences that carry out a variety of tasks.',\n 'Amp is a non-blocking concurrency framework for PHP.',\n 'Android is an operating system built by Google designed for mobile devices.']"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs = get_topic_descs(doc)\n",
    "descs[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def get_topic_url(doc):\n",
    "    \"\"\"\n",
    "    This function retrieve the URL of the topics.\n",
    "    :param doc: Beautifulsoup Object\n",
    "    :return: a list\n",
    "    \"\"\"\n",
    "\n",
    "    selected_class = 'd-flex no-underline'\n",
    "    topic_link_tags = doc.findAll('a', class_ = selected_class)\n",
    "    topic_urls = []\n",
    "    base_url  = 'https://github.com'\n",
    "\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "\n",
    "    return topic_urls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "['https://github.com/topics/3d',\n 'https://github.com/topics/ajax',\n 'https://github.com/topics/algorithm',\n 'https://github.com/topics/amphp',\n 'https://github.com/topics/android']"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_urls = get_topic_url(doc)\n",
    "topic_urls[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's put all together in a single function called `scrape_topics`. The title, description, and url will be saved in  dictionary called `topics_dict` and then converted in a pandas Dataframe for easily using it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def scrape_topics(url):\n",
    "\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(url))\n",
    "\n",
    "    topics_dict = {\n",
    "        'title':get_topic_title(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url':get_topic_url(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try out our function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "       title                                        description  \\\n0         3D  3D modeling is the process of virtually develo...   \n1       Ajax  Ajax is a technique for creating interactive w...   \n2  Algorithm  Algorithms are self-contained sequences that c...   \n3        Amp  Amp is a non-blocking concurrency framework fo...   \n4    Android  Android is an operating system built by Google...   \n\n                                   url  \n0         https://github.com/topics/3d  \n1       https://github.com/topics/ajax  \n2  https://github.com/topics/algorithm  \n3      https://github.com/topics/amphp  \n4    https://github.com/topics/android  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3D</td>\n      <td>3D modeling is the process of virtually develo...</td>\n      <td>https://github.com/topics/3d</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ajax</td>\n      <td>Ajax is a technique for creating interactive w...</td>\n      <td>https://github.com/topics/ajax</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algorithm</td>\n      <td>Algorithms are self-contained sequences that c...</td>\n      <td>https://github.com/topics/algorithm</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Amp</td>\n      <td>Amp is a non-blocking concurrency framework fo...</td>\n      <td>https://github.com/topics/amphp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Android</td>\n      <td>Android is an operating system built by Google...</td>\n      <td>https://github.com/topics/android</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = scrape_topics(url)\n",
    "topics_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(topics_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the top 25 repositories from a topic page\n",
    "\n",
    "Now we have all the function we need for scraping the top 25 repositories of the page. First we will use the `get_topic_page` for scrape the web page."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    \"\"\"\n",
    "    This function scrap a designed webpage at url address and return a parsed BeautifulSoup containing the website\n",
    "    Lib needed:\n",
    "        import requests\n",
    "    :param topic_url: website address to scrap\n",
    "    :return: BeautifulSoup doc\n",
    "    \"\"\"\n",
    "\n",
    "    # download the page\n",
    "    r = requests.get(topic_url)\n",
    "    # check response\n",
    "    if r.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # parse beautiful soup\n",
    "    topic_doc = BeautifulSoup(r.text, 'html.parser')\n",
    "    return topic_doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test the function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "topic_doc = get_topic_page('https://github.com/topics')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next function we implement will convert the number of stars the topic have from string to integer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def parse_star_count(stars_str):\n",
    "    stars_tags = stars_str.strip()\n",
    "    if stars_tags[-1] == 'k':\n",
    "        return int(float(stars_str[:-1]) * 1000)\n",
    "    return int(stars_str)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how the function works. The next lines of code are for retrieve the number of stars. As we can see the and the tag is `a` and the class is `social-count js-social-count`\n",
    "\n",
    "![](https://i.imgur.com/7howgRz.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "'76.3k'"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve 3D topic\n",
    "r = requests.get('https://github.com/topics/3d')\n",
    "topic_doc = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "# Define a selection tag\n",
    "a_selection_class = 'social-count js-social-count'\n",
    "star_tags = topic_doc.findAll('a',class_ = a_selection_class)\n",
    "star_tags[0].text.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "76300"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_star_count(star_tags[0].text.strip())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Second step consists on write a function that return all the information about the repositories. As we saw on the image before all the information are contained on the tag `a`. As shown on the picture for get the url of the repository we can use the `href` class to get it.\n",
    "\n",
    "![](https://i.imgur.com/7howgRz.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next function we prepared is take together some of the previous function to get all the information we want about one repository."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def get_repo_info(h1_tag, star_tags):\n",
    "    # return all the info about the repo\n",
    "    a_tags = h1_tag.findAll('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = 'https://github.com' + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tags.text.strip())\n",
    "    return username, repo_name, repo_url, stars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's testing tha function. As we can see on the image below we can select the `h3` tag and the `f3 color-fg-muted text-normal lh-condensed` class.\n",
    "\n",
    "![](https://i.imgur.com/BeWTUYC.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "('mrdoob', 'three.js', 'https://github.com/mrdoob/three.js', 76300)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "repo_tags = topic_doc.findAll('h3', class_ = h3_selection_class)\n",
    "get_repo_info(repo_tags[0], star_tags[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One of the last function we are create is `get_topic_repos` that take a bs file and extract the information we need and then return a pandas dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.findAll('h3', class_ = h3_selection_class)\n",
    "\n",
    "    a_selection_class = 'social-count js-social-count'\n",
    "    star_tags = topic_doc.findAll('a',class_ = a_selection_class)\n",
    "\n",
    "    topic_repo_dic = {'username': [],'repo_name': [],'stars': [],'repo_url': []}\n",
    "\n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repo_dic['username'].append(repo_info[0])\n",
    "        topic_repo_dic['repo_name'].append(repo_info[1])\n",
    "        topic_repo_dic['repo_url'].append(repo_info[2])\n",
    "        topic_repo_dic['stars'].append(repo_info[3])\n",
    "\n",
    "    return pd.DataFrame(topic_repo_dic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last function we create check if the csv file already exist. If the file is not present the function will retrieve the information about the repository, convert it on dataframe through pandas and save it on a specific path."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url, path):\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        print('the file {} already exists. Skipping...'.format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting all together\n",
    "- We have a function to get the list of topics\n",
    "- We have a function to create a CSV file for scraped repos from a topics page\n",
    "- Let's create a function to put them togheter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scrape_topics_repos(url):\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics(url)\n",
    "    folder_name = \"Scraped_csv\"\n",
    "    try:\n",
    "        os.makedirs(folder_name, exist_ok = True)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % folder_name)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % folder_name)\n",
    "\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for {}'.format(row['title']))\n",
    "        scrape_topic(row['url'], folder_name + '/{}.csv'.format(row['title']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's run it to scrape the top repos for the all topics on the first page of https://github.com/topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Successfully created the directory Scraped_csv \n",
      "Scraping top repositories for 3D\n",
      "the file Scraped_csv/3D.csv already exists. Skipping...\n",
      "Scraping top repositories for Ajax\n",
      "the file Scraped_csv/Ajax.csv already exists. Skipping...\n",
      "Scraping top repositories for Algorithm\n",
      "the file Scraped_csv/Algorithm.csv already exists. Skipping...\n",
      "Scraping top repositories for Amp\n",
      "the file Scraped_csv/Amp.csv already exists. Skipping...\n",
      "Scraping top repositories for Android\n",
      "the file Scraped_csv/Android.csv already exists. Skipping...\n",
      "Scraping top repositories for Angular\n",
      "the file Scraped_csv/Angular.csv already exists. Skipping...\n",
      "Scraping top repositories for Ansible\n",
      "the file Scraped_csv/Ansible.csv already exists. Skipping...\n",
      "Scraping top repositories for API\n",
      "the file Scraped_csv/API.csv already exists. Skipping...\n",
      "Scraping top repositories for Arduino\n",
      "the file Scraped_csv/Arduino.csv already exists. Skipping...\n",
      "Scraping top repositories for ASP.NET\n",
      "the file Scraped_csv/ASP.NET.csv already exists. Skipping...\n",
      "Scraping top repositories for Atom\n",
      "the file Scraped_csv/Atom.csv already exists. Skipping...\n",
      "Scraping top repositories for Awesome Lists\n",
      "the file Scraped_csv/Awesome Lists.csv already exists. Skipping...\n",
      "Scraping top repositories for Amazon Web Services\n",
      "the file Scraped_csv/Amazon Web Services.csv already exists. Skipping...\n",
      "Scraping top repositories for Azure\n",
      "the file Scraped_csv/Azure.csv already exists. Skipping...\n",
      "Scraping top repositories for Babel\n",
      "the file Scraped_csv/Babel.csv already exists. Skipping...\n",
      "Scraping top repositories for Bash\n",
      "the file Scraped_csv/Bash.csv already exists. Skipping...\n",
      "Scraping top repositories for Bitcoin\n",
      "the file Scraped_csv/Bitcoin.csv already exists. Skipping...\n",
      "Scraping top repositories for Bootstrap\n",
      "the file Scraped_csv/Bootstrap.csv already exists. Skipping...\n",
      "Scraping top repositories for Bot\n",
      "the file Scraped_csv/Bot.csv already exists. Skipping...\n",
      "Scraping top repositories for C\n",
      "Scraping top repositories for Chrome\n",
      "Scraping top repositories for Chrome extension\n",
      "Scraping top repositories for Command line interface\n",
      "Scraping top repositories for Clojure\n",
      "Scraping top repositories for Code quality\n",
      "Scraping top repositories for Code review\n",
      "Scraping top repositories for Compiler\n",
      "Scraping top repositories for Continuous integration\n",
      "Scraping top repositories for COVID-19\n",
      "Scraping top repositories for C++\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos(url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can check that the CSV where create properly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read and display CSV with pandas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check if the data are correctly. We will read a csv file with pandas as follow."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "    username          repo_name  stars  \\\n0     mrdoob           three.js  76300   \n1     libgdx             libgdx  19300   \n2     pmndrs  react-three-fiber  15800   \n3  BabylonJS         Babylon.js  15300   \n4   aframevr             aframe  13300   \n\n                                      repo_url  \n0           https://github.com/mrdoob/three.js  \n1             https://github.com/libgdx/libgdx  \n2  https://github.com/pmndrs/react-three-fiber  \n3      https://github.com/BabylonJS/Babylon.js  \n4           https://github.com/aframevr/aframe  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>repo_name</th>\n      <th>stars</th>\n      <th>repo_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mrdoob</td>\n      <td>three.js</td>\n      <td>76300</td>\n      <td>https://github.com/mrdoob/three.js</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>libgdx</td>\n      <td>libgdx</td>\n      <td>19300</td>\n      <td>https://github.com/libgdx/libgdx</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pmndrs</td>\n      <td>react-three-fiber</td>\n      <td>15800</td>\n      <td>https://github.com/pmndrs/react-three-fiber</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BabylonJS</td>\n      <td>Babylon.js</td>\n      <td>15300</td>\n      <td>https://github.com/BabylonJS/Babylon.js</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aframevr</td>\n      <td>aframe</td>\n      <td>13300</td>\n      <td>https://github.com/aframevr/aframe</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_df = pd.read_csv(\"Scraped_csv/3D.csv\")\n",
    "Test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"desousa-andreas/scraping-top-repositories-for-topics-on-github\" on https://jovian.ai/\r\n",
      "[jovian] Committed successfully! https://jovian.ai/desousa-andreas/scraping-top-repositories-for-topics-on-github\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "'https://jovian.ai/desousa-andreas/scraping-top-repositories-for-topics-on-github'"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit(project=project_name )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References and future work\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Summary of what we did:\n",
    "* We create helpful function for scraping repositories on github.\n",
    "* We scrape information's the fist page of topic repositories.\n",
    "\n",
    "References to links we found useful:\n",
    "* [Beatifulsoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* [Pandas Documantation](https://pandas.pydata.org/docs/)\n",
    "\n",
    "Ideas for future work:\n",
    "* Implementing a function for scrape on multiple pages.\n",
    "* Scrape also the logo of the repository."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"desousa-andreas/scraping-top-repositories-for-topics-on-github\" on https://jovian.ai/\r\n",
      "[jovian] Committed successfully! https://jovian.ai/desousa-andreas/scraping-top-repositories-for-topics-on-github\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "'https://jovian.ai/desousa-andreas/scraping-top-repositories-for-topics-on-github'"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit(project=project_name )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}